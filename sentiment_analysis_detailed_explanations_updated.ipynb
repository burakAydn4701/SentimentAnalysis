{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a42df0",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with Transformers - Comprehensive Walkthrough\n",
    "\n",
    "This notebook demonstrates how to build a sentiment analysis model using Hugging Face's Transformers library. The notebook includes detailed explanations for every step in the process, from data preprocessing to model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c7f264",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de53fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4c9fd",
   "metadata": {},
   "source": [
    "In this step, we import libraries required for:\n",
    "- Data handling (`pandas`).\n",
    "- Splitting datasets into training, validation, and testing sets (`train_test_split`).\n",
    "- Tokenization, model initialization, and training using Hugging Face's Transformers.\n",
    "- Evaluation using accuracy and F1 scores.\n",
    "- Data visualization (`matplotlib`, `seaborn`).\n",
    "- Regular expressions (`re`) for cleaning text.\n",
    "- Custom dataset creation for PyTorch integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13906a3",
   "metadata": {},
   "source": [
    "#### Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf97a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)    # Remove mentions\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text) # Remove special characters\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cefc5ef",
   "metadata": {},
   "source": [
    "Text preprocessing is essential for consistent and clean input to the model. Here:\n",
    "1. **Non-string handling**: Ensures the input is a string; otherwise, it returns an empty string.\n",
    "2. **Removing URLs**: Eliminates web links using a regex pattern (`http\\S+`).\n",
    "3. **Removing mentions**: Removes mentions such as `@username`.\n",
    "4. **Removing special characters**: Keeps only alphanumeric characters and spaces.\n",
    "5. **Lowercasing**: Converts text to lowercase for uniformity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57360179",
   "metadata": {},
   "source": [
    "#### Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    sentiment_mapping = {'negative': 0, 'positive': 1}\n",
    "    df['Label'] = df['Sentiment'].map(sentiment_mapping)\n",
    "    df['Cleaned_Text'] = df['Text'].apply(clean_text)  # Ensure this column exists\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da4639",
   "metadata": {},
   "source": [
    "Here, we:\n",
    "1. **Load the dataset**: Reads the CSV file into a Pandas DataFrame.\n",
    "2. **Map sentiments**: Converts the textual labels (`negative`, `positive`) into numerical ones (`0`, `1`).\n",
    "3. **Clean the text**: Applies the `clean_text` function to preprocess the raw text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d30e4",
   "metadata": {},
   "source": [
    "#### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5aa08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    train_data, temp_data = train_test_split(df, test_size=0.2, stratify=df['Label'], random_state=42)\n",
    "    val_data, test_data = train_test_split(temp_data, test_size=0.5, stratify=temp_data['Label'], random_state=42)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34238b6",
   "metadata": {},
   "source": [
    "The dataset is split into training, validation, and testing sets using stratified sampling. This ensures the class distribution remains consistent across subsets. The split ratio is 80% training, 10% validation, and 10% testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176fd6c",
   "metadata": {},
   "source": [
    "#### Preprocessing Text for Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f785e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, tokenizer):\n",
    "    encoded = tokenizer(\n",
    "        list(examples['Cleaned_Text']),  # Ensure we pass a list of text data\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    encoded[\"labels\"] = list(examples[\"Label\"])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f1dea7",
   "metadata": {},
   "source": [
    "We tokenize text data using Hugging Face's pre-trained tokenizer:\n",
    "- **Truncation and padding**: Ensures all sequences have a uniform length (max 128 tokens).\n",
    "- **Labels**: Adds the numerical labels to the tokenized output. This step prepares the data for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4443aa",
   "metadata": {},
   "source": [
    "#### Computing Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"f1\": f1_score(labels, predictions, average=\"weighted\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df848667",
   "metadata": {},
   "source": [
    "Evaluation metrics include:\n",
    "- **Accuracy**: The proportion of correctly predicted labels.\n",
    "- **F1 score**: Balances precision and recall, with weighting for class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3605bb",
   "metadata": {},
   "source": [
    "#### Creating a Custom Dataset for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"labels\": self.encodings[\"labels\"][idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b41490",
   "metadata": {},
   "source": [
    "This class integrates tokenized data into PyTorch workflows. It enables:\n",
    "- **Indexing**: Access individual samples.\n",
    "- **Integration**: Seamless usage with PyTorch data loaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbd964",
   "metadata": {},
   "source": [
    "#### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce2f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, val_df, model_name=\"dbmdz/bert-base-turkish-cased\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "    train_encodings = preprocess_function(train_df, tokenizer)\n",
    "    val_encodings = preprocess_function(val_df, tokenizer)\n",
    "\n",
    "    train_dataset = CustomDataset(train_encodings)\n",
    "    val_dataset = CustomDataset(val_encodings)\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    return trainer, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530138c1",
   "metadata": {},
   "source": [
    "We use Hugging Face's `Trainer` to simplify the training loop. Key configurations include:\n",
    "- **Learning rate**: 2e-5 for fine-tuning.\n",
    "- **Batch size**: 16 for both training and evaluation.\n",
    "- **Epochs**: 3 for training.\n",
    "- **Model checkpointing**: Saves the best model based on accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cba5aa",
   "metadata": {},
   "source": [
    "#### Running the Entire Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"/Users/onuryuksel/Desktop/cleaned_balanced_sentiment_data.csv\"  # Update with your dataset path\n",
    "    df = load_and_prepare_data(dataset_path)\n",
    "\n",
    "    # Debug data\n",
    "    print(df[['Cleaned_Text']].head())\n",
    "\n",
    "    train_df, val_df, test_df = split_data(df)\n",
    "\n",
    "    model_name = \"dbmdz/bert-base-turkish-cased\"\n",
    "    trainer, tokenizer = train_model(train_df, val_df, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aaf6ef",
   "metadata": {},
   "source": [
    "Finally, we run the complete pipeline, from data loading to model training. Adjust the `dataset_path` and `model_name` as per your requirements. Verify preprocessing by printing a sample of cleaned text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Weekly Negativity Percentage\n",
    "\n",
    "This section provides a comparison of weekly negativity percentages across three models:\n",
    "- **Model 1**: Results visualized in `skyblue`\n",
    "- **Model 2**: Results visualized in `lightcoral`\n",
    "- **Model 3**: Results visualized in `lightgreen`\n",
    "\n",
    "The bar chart allows for easy comparison of negativity trends over different weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Weekly Negativity Percentage Across Models\n",
    "file_path_1 = '/Users/onuryuksel/Downloads/dataset1result.csv'\n",
    "file_path_2 = '/Users/onuryuksel/Downloads/dataset2result.csv'\n",
    "file_path_3 = '/Users/onuryuksel/Downloads/dataset3result.csv'\n",
    "data_1 = pd.read_csv(file_path_1)\n",
    "data_2 = pd.read_csv(file_path_2)\n",
    "data_3 = pd.read_csv(file_path_3)\n",
    "\n",
    "# Calculate weekly negativity percentages\n",
    "data_1['negative'] = data_1['sentiment'] == 'LABEL_2'\n",
    "data_2['negative'] = data_2['sentiment'] == 'negative'\n",
    "data_3['negative'] = data_3['sentiment'] == 'LABEL_2'\n",
    "\n",
    "weekly_negativity_1 = data_1.groupby('week')['negative'].mean() * 100\n",
    "weekly_negativity_2 = data_2.groupby('week')['negative'].mean() * 100\n",
    "weekly_negativity_3 = data_3.groupby('week')['negative'].mean() * 100\n",
    "\n",
    "weeks = weekly_negativity_1.index.tolist()\n",
    "\n",
    "# Plot the negativity percentages for all datasets\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# First dataset (Model 1)\n",
    "plt.bar([w - 0.2 for w in weeks], weekly_negativity_1.values, width=0.4, label='Model 1', color='skyblue')\n",
    "\n",
    "# Second dataset (Model 2)\n",
    "plt.bar([w + 0.2 for w in weeks], weekly_negativity_2.values, width=0.4, label='Model 2', color='lightcoral')\n",
    "\n",
    "# Third dataset (Model 3)\n",
    "plt.bar(weeks, weekly_negativity_3.values, width=0.4, label='Model 3', color='lightgreen')\n",
    "\n",
    "# Add titles, labels, and legend\n",
    "plt.title('Weekly Negativity Percentage (Comparison)', fontsize=16)\n",
    "plt.xlabel('Week', fontsize=14)\n",
    "plt.ylabel('Negativity Percentage (%)', fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(weeks, rotation=45)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
